{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe0824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/octoopt/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moctoopt\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy.engine.result\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.ultralytics import add_wandb_callback\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from huggingface_hub import login as hf_login\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(\"../\").resolve()\n",
    "DATA_DIR = ROOT_DIR / \"data\" / \"human_nonhuman\"\n",
    "LOG_DIR = ROOT_DIR / \"logs\"\n",
    "\n",
    "WANDB_PROJECT = \"human-non-human-classification\"\n",
    "WANDB_JOB_TYPE = \"training\"\n",
    "WANDB_TOKEN = os.getenv(\"WANDB_TOKEN\")\n",
    "\n",
    "\n",
    "wandb.login(key=WANDB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d001f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated 'wandb=True'\n",
      "JSONDict(\"/home/octoopt/.config/Ultralytics/settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"/home/octoopt/workspace/projects/learn-from-basics/the-notes/cv/tracking/datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"4a28363b300d4f86a8ec4580dd2079712156257fd00e1b95f3683b059b8ffdd8\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": false,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true,\n",
      "  \"openvino_msg\": true\n",
      "}\n",
      "üí° Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
     ]
    }
   ],
   "source": [
    "!yolo settings wandb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2146c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_exp_name(prefix=\"human_nonhuman\"):\n",
    "    \"\"\"Generates a random experiment name with prefix and padded ID.\"\"\"\n",
    "    run_id = f\"{random.randint(1, 999):03d}\"\n",
    "    timestamp = datetime.now().strftime(\"%y%m%d\") # YYMMDD\n",
    "    return f\"{prefix}_{timestamp}_{run_id}\"\n",
    "\n",
    "def _normalize_model_name(model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes model name to be used as a safe filename.\n",
    "    Example: 'ultralytics/yolo11n-cls.pt' -> 'yolo11n_cls'\n",
    "    \"\"\"\n",
    "    # 1. Use Path to extract the filename without the extension\n",
    "    # Path('path/to/model.pt').stem -> 'model'\n",
    "    clean_name = Path(model_name).stem\n",
    "    \n",
    "    # 2. Replace any non-alphanumeric character with an underscore\n",
    "    # This handles dots, slashes, dashes, and even weird characters\n",
    "    clean_name = re.sub(r'[^a-zA-Z0-9]', '_', clean_name)\n",
    "    \n",
    "    # 3. Clean up: Collapse multiple underscores into one, \n",
    "    # trim edges, and lowercase for consistency\n",
    "    clean_name = re.sub(r'_+', '_', clean_name).strip('_').lower()\n",
    "    \n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6779ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-cls.pt to 'yolo11s-cls.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.0MB 23.5MB/s 0.6s0.5s<0.1ss\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/wandb/run-20260104_094716-vyf3ggch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/octoopt/human-non-human-classification/runs/vyf3ggch' target=\"_blank\">yolo11s_cls_260104_086</a></strong> to <a href='https://wandb.ai/octoopt/human-non-human-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/octoopt/human-non-human-classification' target=\"_blank\">https://wandb.ai/octoopt/human-non-human-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/octoopt/human-non-human-classification/runs/vyf3ggch' target=\"_blank\">https://wandb.ai/octoopt/human-non-human-classification/runs/vyf3ggch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.247 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.228 üöÄ Python-3.10.18 torch-2.4.1+cu121 CUDA:0 (Quadro P2000, 4034MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset, degrees=10.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.1, dynamic=False, embed=None, epochs=100, erasing=0.2, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11s_cls_260104_086, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train... found 5973 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... found 1706 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test... found 855 images in 2 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
      "YOLO11s-cls summary: 86 layers, 5,445,570 parameters, 5,445,570 gradients, 12.1 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 573.2¬±260.7 MB/s, size: 8.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train... 5941 images, 32 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5941/5941 6.5Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_000732.png: ignoring corrupt image/label: image size (9, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_000747.png: ignoring corrupt image/label: image size (8, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_000945.png: ignoring corrupt image/label: image size (14, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_001239.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_001598.png: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_002106.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003004.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003079.png: ignoring corrupt image/label: image size (14, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003084.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003124.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003135.png: ignoring corrupt image/label: image size (10, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003136.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003208.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003221.png: ignoring corrupt image/label: image size (14, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003230.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003237.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003239.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003245.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003248.png: ignoring corrupt image/label: image size (10, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003255.png: ignoring corrupt image/label: image size (11, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003257.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003309.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003345.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003347.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003350.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003355.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003356.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003366.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003368.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003369.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003392.png: ignoring corrupt image/label: image size (14, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train/non_human/image_003409.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 325.6¬±143.3 MB/s, size: 9.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... 1693 images, 13 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1693/1693 524.1Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_000823.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_000936.png: ignoring corrupt image/label: image size (10, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_001107.png: ignoring corrupt image/label: image size (8, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_002983.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003053.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003123.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003130.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003172.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003184.png: ignoring corrupt image/label: image size (9, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003246.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003365.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003372.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003406.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      1/100     0.941G     0.3389         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.8it/s 48.4s0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 7.9it/s 3.4s0.1s\n",
      "                   all      0.788          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      2/100     0.941G     0.4617         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 4.0it/s 46.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 7.9it/s 3.4s0.1s\n",
      "                   all      0.756          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      3/100     0.943G     0.6405         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 4.1it/s 45.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 7.9it/s 3.4s0.1s\n",
      "                   all      0.671          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      4/100     0.943G     0.7745         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 4.1it/s 45.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 7.8it/s 3.4s0.1s\n",
      "                   all      0.553          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      5/100     0.943G     0.5949         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.9it/s 47.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.725          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      6/100     0.943G     0.5487         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.777          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      7/100     0.943G     0.4827         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.823          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      8/100     0.943G     0.4196         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.862          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      9/100     0.943G     0.3895         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.871          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     10/100     0.943G     0.3631         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.899          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     11/100     0.943G     0.3253         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.888          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     12/100     0.943G     0.3218         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.892          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     13/100     0.943G     0.2941         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.87          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     14/100     0.943G     0.2915         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.907          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     15/100     0.943G       0.27         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.934          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     16/100     0.943G     0.2578         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.937          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     17/100     0.943G     0.2651         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.948          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     18/100     0.943G     0.2433         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     19/100     0.943G     0.2371         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.937          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     20/100     0.943G     0.2108         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.959          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     21/100     0.943G     0.2015         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.947          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     22/100     0.943G     0.2124         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.955          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     23/100     0.943G     0.1957         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.961          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     24/100     0.943G      0.192         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.959          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     25/100     0.943G     0.2072         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.917          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     26/100     0.943G     0.2025         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.955          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     27/100     0.943G     0.1801         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.957          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     28/100     0.943G     0.1837         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.947          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     29/100     0.945G     0.1675         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.966          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     30/100     0.945G      0.165         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.963          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     31/100     0.945G     0.1559         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.955          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     32/100     0.945G     0.1512         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.964          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     33/100     0.945G     0.1526         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.966          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     34/100     0.945G     0.1633         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.963          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     35/100     0.945G     0.1492         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.971          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     36/100     0.945G     0.1564         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.972          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     37/100     0.945G     0.1413         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.965          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     38/100     0.945G     0.1429         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.96          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     39/100     0.945G     0.1319         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.963          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     40/100     0.945G     0.1197         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.973          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     41/100     0.945G     0.1408         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.962          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     42/100     0.945G     0.1255         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.968          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     43/100     0.945G     0.1322         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.971          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     44/100     0.945G     0.1215         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.968          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     45/100     0.945G     0.1246         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.97          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     46/100     0.945G     0.1314         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.961          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     47/100     0.945G     0.1138         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.973          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     48/100     0.945G     0.1104         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     49/100     0.945G     0.1193         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.975          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     50/100     0.945G     0.1239         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.972          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     51/100     0.945G     0.1025         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.979          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     52/100     0.945G     0.1024         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     53/100     0.945G     0.1094         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.979          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     54/100     0.945G    0.09665         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.979          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     55/100     0.945G     0.1086         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.977          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     56/100     0.945G     0.1065         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.97          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     57/100     0.945G    0.09574         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     58/100     0.945G     0.1035         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.979          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     59/100     0.945G    0.09222         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.978          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     60/100     0.945G    0.09977         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     61/100     0.945G     0.1032         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.978          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     62/100     0.945G     0.1008         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.979          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     63/100     0.945G    0.09279         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.979          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     64/100     0.945G    0.09736         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     65/100     0.945G    0.07963         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     66/100     0.945G    0.08409         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     67/100     0.945G    0.08172         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     68/100     0.945G    0.07637         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     69/100     0.945G    0.07518         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.98          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     70/100     0.945G    0.09242         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.98          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     71/100     0.945G    0.07276         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.981          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     72/100     0.945G    0.07498         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     73/100     0.945G    0.07044         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     74/100     0.945G    0.06889         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all       0.98          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     75/100     0.945G     0.0656         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     76/100     0.945G     0.0648         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.985          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     77/100     0.945G    0.06997         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.981          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     78/100     0.945G    0.06243         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.7it/s 50.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     79/100     0.945G    0.06388         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.982          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     80/100     0.945G    0.06239         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.2s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 4.0s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     81/100     0.945G    0.07377         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.984          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     82/100     0.945G    0.05899         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 52.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 4.0s0.1s\n",
      "                   all      0.985          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     83/100     0.945G    0.05563         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.3s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 4.0s0.2s\n",
      "                   all      0.987          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     84/100     0.945G    0.05349         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.985          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     85/100     0.945G    0.05644         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 3.9s0.1s\n",
      "                   all      0.986          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     86/100     0.945G     0.0497         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.2s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 3.9s0.2s\n",
      "                   all      0.988          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     87/100     0.945G    0.05119         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.5s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     88/100     0.945G    0.05873         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     89/100     0.945G    0.05377         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.984          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     90/100     0.945G    0.04535         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     91/100     0.945G     0.0467         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.5s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     92/100     0.945G    0.04792         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.983          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     93/100     0.945G    0.04619         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.984          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     94/100     0.945G    0.04547         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 4.0s0.1s\n",
      "                   all      0.986          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     95/100     0.945G    0.04065         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.9it/s 3.9s0.1s\n",
      "                   all      0.985          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     96/100     0.945G    0.04537         21        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 186/186 3.6it/s 51.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.8it/s 4.0s0.1s\n",
      "                   all      0.985          1\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 86, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "96 epochs completed in 1.466 hours.\n",
      "Optimizer stripped from /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/last.pt, 11.0MB\n",
      "Optimizer stripped from /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.pt, 11.0MB\n",
      "\n",
      "Validating /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.pt...\n",
      "Ultralytics 8.3.228 üöÄ Python-3.10.18 torch-2.4.1+cu121 CUDA:0 (Quadro P2000, 4034MiB)\n",
      "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train... found 5973 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... found 1706 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test... found 855 images in 2 classes ‚úÖ \n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 27/27 6.7it/s 4.0s0.2s\n",
      "                   all      0.988          1\n",
      "Speed: 0.1ms preprocess, 2.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0006</td></tr><tr><td>lr/pg1</td><td>0.0006</td></tr><tr><td>lr/pg2</td><td>0.0006</td></tr><tr><td>metrics/accuracy_top1</td><td>0.98464</td></tr><tr><td>metrics/accuracy_top5</td><td>1</td></tr><tr><td>model/GFLOPs</td><td>12.137</td></tr><tr><td>model/parameters</td><td>5445570</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.905</td></tr><tr><td>train/loss</td><td>0.04537</td></tr><tr><td>val/loss</td><td>0.04556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11s_cls_260104_086</strong> at: <a href='https://wandb.ai/octoopt/human-non-human-classification/runs/vyf3ggch' target=\"_blank\">https://wandb.ai/octoopt/human-non-human-classification/runs/vyf3ggch</a><br> View project at: <a href='https://wandb.ai/octoopt/human-non-human-classification' target=\"_blank\">https://wandb.ai/octoopt/human-non-human-classification</a><br>Synced 5 W&B file(s), 15 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/wandb/run-20260104_094716-vyf3ggch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 96 that is less than the current step 97. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 üöÄ Python-3.10.18 torch-2.4.1+cu121 CUDA:0 (Quadro P2000, 4034MiB)\n",
      "YOLO11s-cls summary (fused): 47 layers, 5,436,690 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train... found 5973 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... found 1706 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test... found 855 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 411.2¬±130.4 MB/s, size: 9.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... 1693 images, 13 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1693/1693 1.9Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_000823.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_000936.png: ignoring corrupt image/label: image size (10, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_001107.png: ignoring corrupt image/label: image size (8, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_002983.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003053.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003123.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003130.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003172.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003184.png: ignoring corrupt image/label: image size (9, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003246.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003365.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003372.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003406.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 106/106 26.5it/s 4.0s0.1s\n",
      "                   all      0.988          1\n",
      "Speed: 0.1ms preprocess, 2.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/notebooks/runs/classify/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a YOLO classification model (n is the fastest/smallest)\n",
    "model_name = \"yolo11s-cls.pt\"\n",
    "model = YOLO(model_name)  # or \"yolov8n-cls.pt\"\n",
    "\n",
    "# Generates a 3-digit padded number (001, 042, etc.)\n",
    "_exp_name = _normalize_model_name(model_name=model_name)\n",
    "exp_name = random_exp_name(prefix=_exp_name)\n",
    "\n",
    "wandb.init(\n",
    "    project=WANDB_PROJECT, \n",
    "    name=exp_name, \n",
    "    job_type=WANDB_JOB_TYPE,\n",
    "    dir=str(LOG_DIR) \n",
    ")\n",
    "\n",
    "results = model.train(\n",
    "    data=str(DATA_DIR / \"yolo_dataset\"),\n",
    "    epochs=100,\n",
    "    imgsz=224,             \n",
    "    batch=64,               # Increased for stability\n",
    "    workers=8,\n",
    "    device=0,\n",
    "    amp=True,\n",
    "    \n",
    "    # --- Optimization (Lower LR for AdamW) ---\n",
    "    optimizer=\"AdamW\",     \n",
    "    lr0=0.001,              # Lowered from 0.01 to fix the \"V-dip\"\n",
    "    lrf=0.01,\n",
    "    warmup_epochs=5.0,      # Longer transition period\n",
    "    patience=15,            # Give it more time to recover from plateaus\n",
    "    \n",
    "    # --- Data Augmentation (Face Optimized) ---\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=10.0,\n",
    "    translate=0.1,\n",
    "    scale=0.2,              # Reduced from 0.5 to keep faces larger\n",
    "    shear=1.0,              # Reduced to prevent extreme face distortion\n",
    "    fliplr=0.5,\n",
    "    flipud=0.0,\n",
    "    auto_augment=\"randaugment\", \n",
    "    erasing=0.2,\n",
    "    \n",
    "    # --- Saving & Checkpoints ---\n",
    "    project=LOG_DIR / WANDB_PROJECT,\n",
    "    name=exp_name,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    val=True,\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "\n",
    "    # --- Regularization ---\n",
    "    dropout=0.15,           # Slightly increased\n",
    "    label_smoothing=0.1,    # Added to improve generalization\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Finalize\n",
    "metrics = model.val()\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3579929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validation Set Results ---\n",
      "Ultralytics 8.3.228 üöÄ Python-3.10.18 torch-2.4.1+cu121 CUDA:0 (Quadro P2000, 4034MiB)\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train... found 5973 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... found 1706 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test... found 855 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 258.4¬±61.4 MB/s, size: 9.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... 1693 images, 13 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1693/1693 1.8Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_000823.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_000936.png: ignoring corrupt image/label: image size (10, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_001107.png: ignoring corrupt image/label: image size (8, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_002983.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003053.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003123.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003130.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003172.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003184.png: ignoring corrupt image/label: image size (9, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003246.png: ignoring corrupt image/label: image size (10, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003365.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003372.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val/non_human/image_003406.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 106/106 27.2it/s 3.9s0.1s\n",
      "                   all      0.988          1\n",
      "Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/notebooks/runs/classify/val2\u001b[0m\n",
      "--- Test Set Results ---\n",
      "Ultralytics 8.3.228 üöÄ Python-3.10.18 torch-2.4.1+cu121 CUDA:0 (Quadro P2000, 4034MiB)\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/train... found 5973 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/val... found 1706 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test... found 855 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.1 ms, read: 439.9¬±178.3 MB/s, size: 10.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test... 851 images, 4 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 851/851 1.0Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mtest: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test/non_human/image_000306.png: ignoring corrupt image/label: image size (15, 8) <10 pixels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test/non_human/image_003250.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test/non_human/image_003251.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test/non_human/image_003367.png: ignoring corrupt image/label: image size (11, 9) <10 pixels\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 24.1it/s 2.2s0.1s\n",
      "                   all      0.986          1\n",
      "Speed: 0.1ms preprocess, 2.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/notebooks/runs/classify/val3\u001b[0m\n",
      "Final Test Top-1 Accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "# 1. Validate on the standard validation set (happens automatically, but good to be explicit)\n",
    "print(\"--- Validation Set Results ---\")\n",
    "val_metrics = model.val(split='val') \n",
    "\n",
    "# 2. Validate on the TEST set (Your final unbiased metrics)\n",
    "print(\"--- Test Set Results ---\")\n",
    "test_metrics = model.val(split='test')\n",
    "\n",
    "# 3. Print the top-1 accuracy for the test set\n",
    "print(f\"Final Test Top-1 Accuracy: {test_metrics.top1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123a16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 üöÄ Python-3.10.18 torch-2.4.1+cu121 CPU (Intel Core(TM) i9-8950HK 2.90GHz)\n",
      "üí° ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (10.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<=1.19.1', 'onnxslim>=0.1.71'] not found, attempting AutoUpdate...\n",
      "\u001b[2mUsing Python 3.10.18 environment at: /home/octoopt/anaconda3/envs/turlio\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m10 packages\u001b[0m \u001b[2min 459ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 1.27s\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 1.89s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 197ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1monnx\u001b[0m\u001b[2m==1.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnx\u001b[0m\u001b[2m==1.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxslim\u001b[0m\u001b[2m==0.1.82\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 4.2s\n",
      "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 4.9s, saved as '/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.onnx' (20.8 MB)\n",
      "\n",
      "Export complete (5.1s)\n",
      "Results saved to \u001b[1m/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.onnx imgsz=224  \n",
      "Validate:        yolo val task=classify model=/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.onnx imgsz=224 data=/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset  \n",
      "Visualize:       https://netron.app\n",
      "Model exported to: /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_path = model.export(format=\"onnx\", imgsz=224) \n",
    "print(f\"Model exported to: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dbdb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    \"\"\"Preprocesses image to match YOLOv11-cls requirements.\"\"\"\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Normalize: Convert to float32 and scale to [0, 1]\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Channel First (H, W, C) -> (C, H, W)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    \n",
    "    # Add Batch dimension (C, H, W) -> (1, C, H, W)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def evaluate_onnx_classification(onnx_model_path, test_dir):\n",
    "    # 1. Start ONNX Runtime Session\n",
    "    providers = ['CPUExecutionProvider'] # or ['CUDAExecutionProvider'] if you have GPU ORT\n",
    "    session = ort.InferenceSession(onnx_model_path, providers=providers)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    test_path = Path(test_dir)\n",
    "    # Get class names from folders\n",
    "    classes = sorted([d.name for d in test_path.iterdir() if d.is_dir()])\n",
    "    class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(f\"Evaluating {onnx_model_path} on {test_dir}...\")\n",
    "    \n",
    "    # 2. Iterate through class folders\n",
    "    for class_name in classes:\n",
    "        class_dir = test_path / class_name\n",
    "        image_paths = list(class_dir.glob(\"*.[jJ][pP][gG]\")) + list(class_dir.glob(\"*.[pP][nN][gG]\"))\n",
    "        \n",
    "        for img_path in tqdm(image_paths, desc=f\"Class: {class_name}\"):\n",
    "            # Preprocess\n",
    "            input_tensor = preprocess_image(img_path)\n",
    "            \n",
    "            # Inference\n",
    "            outputs = session.run(None, {input_name: input_tensor})\n",
    "            \n",
    "            # Post-process (Softmax/Argmax)\n",
    "            logits = outputs[0]\n",
    "            predicted_idx = np.argmax(logits)\n",
    "            \n",
    "            # Check accuracy\n",
    "            if predicted_idx == class_to_idx[class_name]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f} ({correct}/{total})\")\n",
    "    print(\"-\" * 30)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e112c91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.onnx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa5262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/logs/human-non-human-classification/yolo11s_cls_260104_086/weights/best.onnx on /home/octoopt/workspace/projects/learn-from-basics/compvision_learning/data/human_nonhuman/yolo_dataset/test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class: human: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433/433 [00:02<00:00, 149.96it/s]\n",
      "Class: non_human: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 418/418 [00:03<00:00, 115.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Test Accuracy: 0.9824 (836/851)\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.982373678025852"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Execute ---\n",
    "ONNX_PATH = onnx_path\n",
    "TEST_DATA_DIR = DATA_DIR / \"yolo_dataset/test\"\n",
    "\n",
    "evaluate_onnx_classification(ONNX_PATH, TEST_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49ea0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65850916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "import os\n",
    "\n",
    "# Login using token from .env or manual input\n",
    "hf_login(token=os.getenv(\"HF_TOKEN\")) # You already have this import as hf_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b1e639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# 1. Configuration (Dynamically linked to your training variables)\n",
    "repo_id = \"8Opt/yolo11-human-nonhuman-cls\"\n",
    "\n",
    "# Construct paths using the log_dir and exp_name from your training cell\n",
    "# Adjust the 'yolo_classification' part if you changed your project name in model.train()\n",
    "weights_dir = LOG_DIR / \"human-non-human-classification\" / exp_name / \"weights\"\n",
    "\n",
    "model_pt_path = str(weights_dir / \"best.pt\")\n",
    "model_onnx_path = str(weights_dir / \"best.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f556ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading models from yolo11s_cls_260104_086...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913c4eb285de4eeab06c8fd6efbbfe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7df767f6494f2aa2da8e9e88b6219b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b39f87288d4e9ba8d09db8147831af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bfd40f1bdc47d69158804a584743e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model successfully pushed to: https://huggingface.co/8Opt/yolo11n-human-nonhuman-cls\n"
     ]
    }
   ],
   "source": [
    "api = HfApi()\n",
    "\n",
    "# 2. Create/Update Repo\n",
    "api.create_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True)\n",
    "\n",
    "# 3. Upload Model Files\n",
    "print(f\"Uploading models from {exp_name}...\")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=model_pt_path,\n",
    "    path_in_repo=\"best.pt\",\n",
    "    repo_id=repo_id,\n",
    ")\n",
    "\n",
    "if os.path.exists(model_onnx_path):\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=model_onnx_path,\n",
    "        path_in_repo=\"model.onnx\",\n",
    "        repo_id=repo_id,\n",
    "    )\n",
    "\n",
    "# 4. Create and Upload a professional Model Card (README.md)\n",
    "model_card_content = f\"\"\"\n",
    "---\n",
    "license: mit\n",
    "library_name: ultralytics\n",
    "tags:\n",
    "- real-time\n",
    "- yolo\n",
    "- yolo11\n",
    "- classification\n",
    "- human-detection\n",
    "metrics:\n",
    "- accuracy: 0.9824\n",
    "---\n",
    "\n",
    "# YOLOv11n Human vs Non-Human Classification\n",
    "\n",
    "This is a fine-tuned **YOLOv11s-cls** model for binary classification.\n",
    "\n",
    "## üìä Performance\n",
    "- **Test Accuracy**: 98.24% (836/851 correctly classified)\n",
    "- **Dataset**: Human faces vs. Non-human (Statues, Art, Anime, Gaming)\n",
    "- **Experiment ID**: `{exp_name}`\n",
    "\n",
    "## üöÄ Model Usage\n",
    "\n",
    "### 1. Using Ultralytics (Python)\n",
    "The easiest way to use the trained PyTorch model:\n",
    "\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model = YOLO('path/to/best.pt')\n",
    "\n",
    "# Predict on an image\n",
    "results = model('image.jpg')\n",
    "\n",
    "# Process results\n",
    "for result in results:\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    print(f\"Top-1 class: {{result.names[probs.top1]}}\")\n",
    "    print(f\"Confidence: {{probs.top1conf:.2f}}\")\n",
    "```\n",
    "\n",
    "### 2. Using YOLO CLI\n",
    "```bash\n",
    "yolo classify predict model=path/to/best.pt source='image.jpg'\n",
    "```\n",
    "\n",
    "### 3. Using ONNX Runtime\n",
    "For production or edge deployment without PyTorch:\n",
    "\n",
    "```python\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Initialize session\n",
    "session = ort.InferenceSession(\"model.onnx\")\n",
    "\n",
    "# Preprocess (Resize to 224x224, normalize [0, 1], CHW format)\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "img = cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (224, 224))\n",
    "img = img.astype(np.float32) / 255.0\n",
    "img = img.transpose(2, 0, 1)[np.newaxis, :]  # Add batch dim\n",
    "\n",
    "# Run Inference\n",
    "outputs = session.run(None, {{\"images\": img}})\n",
    "predicted_idx = np.argmax(outputs[0]) \n",
    "print(f\"Predicted Class Index: {{predicted_idx}}\")\n",
    "```\n",
    "\n",
    "## üìà Baseline Metrics (04/01/2026)\n",
    "- **Model**: YOLOv11n-cls\n",
    "- **Input Size**: 224x224\n",
    "- **Test Accuracy**: 98.24%\n",
    "\"\"\"\n",
    "\n",
    "with open(\"temp_README.md\", \"w\") as f: f.write(model_card_content)\n",
    "\n",
    "api.upload_file( path_or_fileobj=\"temp_README.md\", path_in_repo=\"README.md\", repo_id=repo_id, )\n",
    "\n",
    "print(f\"‚úÖ Model successfully pushed to: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d68305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4b470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fdd2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turlio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
